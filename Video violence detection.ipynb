{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78238149",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import tensorboard\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2787e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802ed82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c37182af",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = './Result_hockey/'\n",
    "IMG_SIZE = 100\n",
    "def extract_frames(folder):\n",
    "    c = 0\n",
    "    for folders in os.listdir(folder):\n",
    "        print(folders)\n",
    "        folder_path = os.path.join(folder, folders)\n",
    "        for files in tqdm(os.listdir(folder_path)):\n",
    "            path = os.path.join(folder_path, files)\n",
    "            cap = cv2.VideoCapture(path)\n",
    "            success = True\n",
    "            while success:\n",
    "                success, image = cap.read()\n",
    "                if not success:\n",
    "                    break\n",
    "                    \n",
    "                cv2.resize(cv2.imwrite(OUTPUT_PATH + str(c) + '.jpg', image),(IMG_SIZE, IMG_SIZE))\n",
    "                c += 1\n",
    "        print(c)\n",
    "        print('DONE: ' + folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d73586c",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_frames('./movies_fight/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164d28b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_frames('./Hockey_fight/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29d29635",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIM = 'SGD'\n",
    "LR = 0.01\n",
    "decay = 1e-6\n",
    "EPOCHS = 25\n",
    "BATCH_SIZE=5\n",
    "LOSS = 'categorical_crossentropy'\n",
    "NUM_FRAMES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d2b3f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset():\n",
    "    dataset = []\n",
    "    images = []\n",
    "    limit = 0\n",
    "    count = 0\n",
    "    \n",
    "    for frames in tqdm(os.listdir('./Result_hockey/')):\n",
    "        path = os.path.join('./Result_hockey/',frames)\n",
    "        img = cv2.resize(cv2.imread(path),(IMG_SIZE,IMG_SIZE))\n",
    "        #img = np.array(img,dtype = 'float32')/255\n",
    "        images.append(np.array(img))\n",
    "        limit += 1\n",
    "        count += 1\n",
    "        if limit == NUM_FRAMES:\n",
    "            limit = 0\n",
    "            if(count<20499):\n",
    "                dataset.append(np.array([images, np.array([0, 1])]))\n",
    "            else:\n",
    "                dataset.append(np.array([images, np.array([1, 0])]))\n",
    "            images = []\n",
    "    shuffle(dataset)\n",
    "    np.save('dataset_hockey.npy',dataset)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ad11f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9ffab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f60fc4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                        | 0/41056 [00:00<?, ?it/s]<ipython-input-10-1f5d7af27503>:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  dataset.append(np.array([images, np.array([0, 1])]))\n",
      " 50%|█████████████████████████████████████▍                                     | 20464/41056 [00:42<00:43, 478.45it/s]<ipython-input-10-1f5d7af27503>:19: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  dataset.append(np.array([images, np.array([1, 0])]))\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 41056/41056 [01:23<00:00, 492.50it/s]\n"
     ]
    }
   ],
   "source": [
    "data = create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "338183f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model creation\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Conv2D, Dense, Flatten, MaxPooling2D, TimeDistributed, Reshape, MaxPooling3D,GRU\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73b198cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 10, 100, 100, 64)  1792      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 10, 98, 98, 64)    36928     \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 10, 49, 49, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 47, 47, 64)    36928     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 10, 23, 23, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 10, 21, 21, 64)    36928     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 10, 10, 10, 64)    0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 10, 6400)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 64)                1646848   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 1,765,730\n",
      "Trainable params: 1,765,730\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3,3), activation='relu',input_shape=(10,IMG_SIZE,IMG_SIZE,3),padding='same'))\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(MaxPooling3D((1,2,2)))\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(MaxPooling3D((1,2,2)))\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(MaxPooling3D((1,2,2)))\n",
    "#model.summary()\n",
    "model.add(Reshape((10, 6400)))\n",
    "\n",
    "lstm_fw = LSTM(units = 32)\n",
    "lstm_bw = LSTM(units = 32, go_backwards = True)\n",
    "\n",
    "model.add(Bidirectional(lstm_fw,backward_layer = lstm_bw))\n",
    "\n",
    "#Dense layers\n",
    "\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(32, activation = 'relu'))\n",
    "model.add(Dense(2, activation = 'sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b387266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 10, 100, 100, 64)  1792      \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 10, 98, 98, 64)    36928     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_6 (MaxPooling3 (None, 10, 49, 49, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 10, 47, 47, 64)    36928     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_7 (MaxPooling3 (None, 10, 23, 23, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 10, 21, 21, 64)    36928     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_8 (MaxPooling3 (None, 10, 10, 10, 64)    0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 10, 6400)          0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 64)                1241472   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 1,360,354\n",
      "Trainable params: 1,360,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3,3), activation='relu',input_shape=(10,IMG_SIZE,IMG_SIZE,3),padding='same'))\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(MaxPooling3D((1,2,2)))\n",
    "tf.keras.layers.BatchNormalization()\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(MaxPooling3D((1,2,2)))\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(MaxPooling3D((1,2,2)))\n",
    "#model.summary()\n",
    "model.add(Reshape((10, 6400)))\n",
    "\n",
    "#lstm_fw = LSTM(units = 32)\n",
    "#lstm_bw = LSTM(units = 32, go_backwards = True)\n",
    "#gru = tf.keras.layers.GRU(64)\n",
    "#model.add(Bidirectional(lstm_fw,backward_layer = lstm_bw))\n",
    "model.add(GRU(units = 64))\n",
    "#Dense layers\n",
    "\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(32, activation = 'relu'))\n",
    "model.add(Dense(2, activation = 'sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e308e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('dataset_hockey.npy',allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7a2525",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.load('dataset_movie.npy',allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "463f8563",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, train_size = 0.9, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171de471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3e7b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3fc120",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array([i[0] for i in test_data]).reshape(-1,10,IMG_SIZE,IMG_SIZE,3)\n",
    "Y_test = np.array([i[1] for i in test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b55c639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1108200000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.nbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9a455924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1056.8618774414062"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1108200000/(1024))/1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "29e936c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 8.26 GiB for an array with shape (3694, 10, 100, 100, 3) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-2e9074649135>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mx_valid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_valid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 8.26 GiB for an array with shape (3694, 10, 100, 100, 3) and data type float64"
     ]
    }
   ],
   "source": [
    "X = X.astype('float')/255\n",
    "x_valid = x_valid.astype('float')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da586250",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([i[0] for i in train]).reshape(-1, 10, IMG_SIZE, IMG_SIZE, 3)\n",
    "Y = np.array([i[1] for i in train])\n",
    "x_valid = np.array([i[0] for i in test]).reshape(-1, 10, IMG_SIZE, IMG_SIZE, 3)\n",
    "y_valid = np.array([i[1] for i in test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b31bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d606b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a8ec460",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.SGD(learning_rate = LR)\n",
    "model.compile(loss = LOSS, optimizer = opt, metrics = ['accuracy'])\n",
    "NAME = 'CNN-BiLSTM-{}'.format(int(time.time()))\n",
    "tensorboard = TensorBoard(log_dir = 'logs/{}'.format(NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f71895fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OPTIM = 'SGD'\n",
    "#LR = 0.01\n",
    "# decay = 1e-6\n",
    "# EPOCHS = 25\n",
    "# BATCH_SIZE=5\n",
    "# LOSS = 'categorical_crossentropy'\n",
    "# NUM_FRAMES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "969709e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "739/739 [==============================] - 110s 149ms/step - loss: 0.6946 - accuracy: 0.4940 - val_loss: 0.6935 - val_accuracy: 0.4745\n",
      "Epoch 2/25\n",
      "739/739 [==============================] - 108s 146ms/step - loss: 0.6942 - accuracy: 0.5008 - val_loss: 0.6960 - val_accuracy: 0.4745\n",
      "Epoch 3/25\n",
      "739/739 [==============================] - 112s 151ms/step - loss: 0.6943 - accuracy: 0.4930 - val_loss: 0.6948 - val_accuracy: 0.4745\n",
      "Epoch 4/25\n",
      "675/739 [==========================>...] - ETA: 9s - loss: 0.6944 - accuracy: 0.4895"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-1a38fa897757>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtensorboard\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X,Y,epochs = EPOCHS,validation_data = (x_valid,y_valid), batch_size = BATCH_SIZE, verbose = 1, callbacks = [tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f1459bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model.save('GRU.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafac149",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4476539e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804959f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape,Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c4c3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_valid,y_valid,batch_size = 5,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd097b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test,Y_test,batch_size = 5,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8a4c96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [0.599,0.6245,0.6811,0.7718,0.8519,0.8928,0.9161,0.9329,0.9478,0.9559,0.9662,0.9748,0.9859,0.9789,0.9921,0.959,0.9954,0.9870,0.935,0.9984,0.9997,0.9997,1,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "237e73e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = [i for i in range(25)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36df6eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'accuracy')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epoch,a)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d10616",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
